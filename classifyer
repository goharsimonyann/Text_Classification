# Ներմուծենք գրադարանները
import numpy as np
import pandas as pd
import re
import pickle
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.tokenize import sent_tokenize
from sklearn.datasets import load_files
#import simplemma
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import make_scorer, roc_curve, roc_auc_score
from sklearn.metrics import precision_recall_fscore_support as score
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.multiclass import OneVsRestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC, LinearSVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB

# Քաշենք հետևյալ ֆայլերը
nltk.download('stopwords')
nltk.download('punkt')

train_data = pd.read_csv(r"C:\Users\USER\Desktop\classifying-ilur-news-2022\train.csv")   # ""-ի մեջ՝ train.csv ֆայլի հասցեն ձեր համակարգչի վրա
test_data = pd.read_csv(r"C:\Users\USER\Desktop\classifying-ilur-news-2022\test.csv")   # ""-ի մեջ՝ test.csv ֆայլի հասցեն ձեր համակարգչի վրա

# Հեռացնենք հատուկ նշանները/կետադրությունը տեքստերից
def special_char(text):
  reviews = ''
  for x in text:
    if x.isalnum():
      reviews = reviews + x
    else:
      reviews = reviews + ' '
  return reviews

train_data['Text'] = train_data['Text'].apply(special_char)

# Lowercase
def convert_lower(text):
   return text.lower()

train_data['Text'] = train_data['Text'].apply(convert_lower)

# Հեռացնենք stopwords-ը` տեքստերը դարձնելով list-եր
def remove_stopwords(text):
  stop_words = set(stopwords.words('armenian'))
  words = word_tokenize(text)
  return [x for x in words if x not in stop_words]
train_data['Text'] = train_data['Text'].apply(remove_stopwords)

# Lemmatising՝ տեքստերի բառերը բերենք իրենց ուղիղ ձևերին (հայերենի համար դեռ չի աշխատում)
#langdata = simplemma.load_data('hy')
#train_data['Text'] = [simplemma.lemmatize(t, langdata) for t in train_data['Text']]

# Տեքստերը նորից դարձնենք string-եր
ls = []
for x in train_data['Text']:
    s = ' '.join([str(item) for item in x])
    ls.append(s)
train_data['Text'] = ls

train_data

# Fit Bag (Мешок слов)
x = train_data['Text']
y = train_data['Category']

x = np.array(train_data.iloc[:,0].values)
y = np.array(train_data.Category.values)
cv = CountVectorizer(max_features = 5000)
x = cv.fit_transform(train_data.Text).toarray()
print("X.shape = ",x.shape)
print("y.shape = ",y.shape)

# Բաժանենք տեքստերը 2 խմբի՝ ուսուցման և ստուգման համար
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0, shuffle = True)
print(len(x_train))
print(len(x_test))

# Ստեղծենք դատարկ list՝ հետագայում մեր ալգորիթմների գնահատման չափանիշները ավելացնելու համար
perform_list = [ ]

# Ֆունկցիա՝ կլասսիֆիկացիայի մի քանի ալգորիթմներ կիրառելու և դրանց աշխատանքը գնահատելու համար
def run_model(model_name, est_c, est_pnlty):
    mdl=''
    if model_name == 'Logistic Regression':
        mdl = LogisticRegression()
    elif model_name == 'Random Forest':
        mdl = RandomForestClassifier(n_estimators=100 ,criterion='entropy' , random_state=0)
    elif model_name == 'Multinomial Naive Bayes':
        mdl = MultinomialNB(alpha=1.0,fit_prior=True)
    elif model_name == 'Support Vector Classifer':
        mdl = SVC()
    elif model_name == 'Decision Tree Classifier':
        mdl = DecisionTreeClassifier()
    elif model_name == 'K Nearest Neighbour':
        mdl = KNeighborsClassifier(n_neighbors=10 , metric= 'minkowski' , p = 4)
    elif model_name == 'Gaussian Naive Bayes':
        mdl = GaussianNB()
    oneVsRest = OneVsRestClassifier(mdl)
    oneVsRest.fit(x, y)
    y_pred = oneVsRest.predict(x_test)

    # Չափանիշները
    accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)

    precision, recall, f1score, support = score(y_test, y_pred, average='micro')

    print(f'Test Accuracy Score of Basic {model_name}: % {accuracy}')
    print(f'Precision : {precision}')
    print(f'Recall : {recall}')
    print(f'F1-score : {f1score}')

    perform_list.append(dict([
        ('Model', model_name),
        ('Test Accuracy', round(accuracy, 2)),
        ('Precision', round(precision, 2)),
        ('Recall', round(recall, 2)),
        ('F1', round(f1score, 2))
    ]))

# Օրինակի համար ստուգենք հետևյալ 3 ալգորիթմների աշխատանքը
run_model('Logistic Regression', est_c=None, est_pnlty=None)
run_model('Random Forest', est_c=None, est_pnlty=None)
run_model('Multinomial Naive Bayes', est_c=None, est_pnlty=None)
